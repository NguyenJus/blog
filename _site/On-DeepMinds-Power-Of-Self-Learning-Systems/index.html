<!DOCTYPE html>
<title>On DeepMind&#39;s Power of Self-Learning Systems | Justin&#39;s Journal - RL, AI, and More</title>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="I recently viewed DeepMind’s talk describing their previous successes with AlphaGo, AlphaGoZero, and AlphaStar. In the lecture, DeepMind described not only t...">
<meta name="author" content="Justin Nguyen">
<meta name="generator" content="Jekyll v3.8.5">
<link rel="canonical" href="/blog/On-DeepMinds-Power-Of-Self-Learning-Systems/">
<link rel="stylesheet" href="/blog/assets/css/index.css">
<link rel="stylesheet" href="/blog/assets/css/classes.css">
<link rel="stylesheet" href="/blog/assets/css/contrast.css">
<link rel="alternate" type="application/atom+xml" href="/blog/feed.xml" title="Justin's Journal - RL, AI, and More" />




<body class="light">

<header>
  <h1><a href="/blog/">Justin&#39;s Journal - RL, AI, and More</a></h1>
  <nav><a href="/blog/">Home</a><a href="/blog/archive/">Archive</a><a href="/blog/resources/">Resources</a>

    <a class="page-link" href="https://nguyenjus.github.io">Website</a> <!-- This is custom website edge case -->

  </nav>
  <nav><a class="icon" href="contact"><svg><use xlink:href="/blog/assets/fontawesome/icons.svg#envelope"></use></svg></a><a class="icon" href="https://github.com/nguyenjus"><svg><use xlink:href="/blog/assets/fontawesome/icons.svg#github"></use></svg></a><a class="icon" href="feed.xml"><svg><use xlink:href="/blog/assets/fontawesome/icons.svg#rss"></use></svg></a></nav>
</header>

<article>
  <header><h1><a href="/blog/On-DeepMinds-Power-Of-Self-Learning-Systems/">On DeepMind's Power of Self-Learning Systems</a></h1>
    <time datetime="2019-05-05T22:32:00-04:00">05 May 2019</time>
  </header>
<p>I recently viewed DeepMind’s talk describing their previous successes with AlphaGo, AlphaGoZero, and AlphaStar. In the lecture, DeepMind described not only their successes, but the importance of their research in many applicable fields. As you may know, DeepMind was and still is one of my primary points of inspiration in my journey in AI/vision. I highly recommend anyone interested in AI to watch it:</p>

<iframe width="560" height="315" src="https://www.youtube.com/embed/3N9phq_yZP0" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<h2 id="my-summary"><strong>My Summary</strong></h2>
<p>DeepMind started by attacking Atari’s breakout. Not much was said about the game but it seemed like a relatively easy problem to tackle. Their first huge success was in Go. DeepMind used two systems: AlphaGo and AlphaGoZero. AlphaGo learned by initially watching other people play and attempting to mimic their moves. From mimicking, the AI finds ways to counter the player strategies and goes on to play itself until it becomes the best it can be. AlphaGoZero learned completely by itself; no spectator learning was necessary. These two AI’s went on to beat the human champions of Go. From these achievements came AlphaZero, which was built for chess, but may potentially be applied to any two-player strategy game. AlphaZero dominated the chess world as its predecessor dominated the Go world. From these came AlphaStar which was designed for Starcraft II, a game of imperfect information. Like the others, AlphaStar is ranked above the grandmasters of Starcraft II. Even though DeepMind tackled strategy games, their research can definitely be applied to real life, particularly in the protein folding problem.</p>

<h2 id="why-im-interested"><strong>Why I’m Interested</strong></h2>
<p>The lecture really emphasized why I was originally inspired by DeepMind and why I continue to do the projects I’m undertaking. My field of interest involves providing an AI an environment and having it learn in that environment. Vision allows the AI to extract current game-states or environment-state for analysis in the backend. Learning allows the AI to attempt to solve a problem. As a result, an answer may be produced based on the AI’s understanding of the world it is in. DeepMind did exactly this in AlphaStar. AlphaStar was able to extract information from the map about where the enemy units are, what the enemy is building, what AlphaStar had at ready, etc. It could then predict its probability of winning and take the steps necessary to win the game.</p>

<p>I’m even more invested in what we as humans can learn from AI, something that DeepMind also emphasizes (this was the first time I heard that they share this philosophy). For example, humans have always known that 1. E4 is the best opening move for chess. We know that by statistics, activity of openings, etc. However, AlphaZero showed us that 1. E4 is best because of the potential to play E5 later in the game. A white pawn on E5 encroaches deeply on black’s space, as there is usually a knight on F6 and king-side castle. I myself am not an amazing chess player, but it is fascinating nonetheless.</p>

<p>DeepMind continually emphasized the importance of learning something from their AI, like learning new strategies that spark new metas in Starcraft II. This brings me back to my interest in a Tetris AI. Why am I doing it? Because I primarily want to learn whether a flexible T-spin playstyle is better than a quick back-to-back Tetris playstyle or any of the combo playstyles.</p>

<h2 id="random-notes"><strong>Random Notes</strong></h2>
<p>Expert systems are systems where almost every rule and exception is hard-coded into an AI. This method attempts to create the strongest brute-force AI possible. Learning systems attempt to learn the most optimal way to play with limited or no rules and exceptions. By using well-optimized learning systems, you cut down massively on necessary compute power. Of course, I still believe learning systems can be flawed as they have somewhat human-like behavior and, as such, potential for blunder.</p>

<p>Someone mentioned that, although AlphaStar played below the average grandmaster APM, its peak during battles far exceeded human-like APM. Particularly in game 4 vs MaNa, the human could not keep up because AlphaStar set up a three-pronged attack where it controlled every flank perfectly and quickly. You can see it here: <a href="https://youtu.be/cUTMhmVh1qs?t=6158">DeepMind Starcraft II Demonstration</a> (time 1:42:38). Takeaway: if going for artificial human-like intelligence, keep in mind the limits of human ability and seek to win through intelligence and clever strategies.</p>

<p>DeepMind mentioned that AlphaZero seemed to evolve some sort of creativity - an ability to come up with a novel move that no one had thought of yet. I really like this about learning systems. They have so much creative space since they are learning from scratch that they are bound to find new and enriching ideas.</p>

<p>We are just at the beginning of artificial intelligence and learning. There is so much more to tackle in the coming decades and I’m very glad to soon join in on the research. I hope to one day do cool things like DeepMind (and OpenAI) does.</p>

  
  
</article>


<footer>
  <a class="gray" href="/blog/Typist-for-10fastfingers/">« Typist for 10FastFingers</a>
  <a class="gray" href="/blog/Flasky/">Flasky: ManiaBot's Side Gig »</a>
</footer>




</body>
