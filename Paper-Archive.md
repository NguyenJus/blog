---
layout: page
title: "Paper Archive"
---

A reading list of papers I found or may find interesting. I've summarized the papers I've read or skimmed to a somewhat good understanding understanding.

## In progress

* [AlphaZero](https://science.sciencemag.org/content/362/6419/1140.full?ijkey=XGd77kI6W4rSc&keytype=ref&siteid=sci)

* [AlphaGo Zero](https://www.nature.com/articles/nature24270.epdf?author_access_token=VJXbVjaSHxFoctQQ4p2k4tRgN0jAjWel9jnR3ZoTv0PVW4gB86EEpGqTRDtpIz-2rmo8-KG06gqVobU5NSCFeHILHcVFUeMsbvwS-lxjqQGg98faovwjxeTUgZAUMnRQ)

* [AlphaGo](https://storage.googleapis.com/deepmind-media/alphago/AlphaGoNaturePaper.pdf)

* [Pointer Networks](https://arxiv.org/pdf/1506.03134.pdf)

* [Drafting in MOBAs](https://arxiv.org/pdf/1806.10130.pdf)

* [General Game AI Reinforcement Learning](https://arxiv.org/pdf/1806.02448.pdf)

* [Civ IV Reinforcement Learning](https://pdfs.semanticscholar.org/9f9c/0f114b0c4d9b13ec048507a178fe9b3da4ae.pdf)

* [Hanabi](https://arxiv.org/pdf/1902.00506v1.pdf)

* [Curiosity - Rewardless Exploration](https://pathak22.github.io/noreward-rl/)

* [Apprenticeship Learning](https://ai.stanford.edu/~ang/papers/icml04-apprentice.pdf)

* [Relational Reasoning via Neural Networks](https://arxiv.org/pdf/1706.01427.pdf)

* [NLP vs. Protein Sequences?!](https://www.biorxiv.org/content/10.1101/622803v1)

## Archive

*\* denotes that I may need to recheck the summary.*

*[Learning Abstractions by Transferring Abstract Policies to Grounded State Spaces (2018)](https://www.aaai.org/ocs/index.php/SSS/SSS18/paper/viewFile/17551/15537)  
Unlike humans, robots are unable to abstract important details of any 2D map to navigate the 3D world and vice versa. It may be possible to abstract important aspects of the navigation policy to an abstract policy that can deal with any new map using any of the following or more: isometric path (forward 5 blocks, turn right, etc.), landmarks (including street names), topological path (convert whole map to nodes), and even NLP (voiced instruction abstraction). This research would suggest that we can train AI through supervised learning easier as the instructions are abstracted and the bulk of the state space is up to the agent to discover.
